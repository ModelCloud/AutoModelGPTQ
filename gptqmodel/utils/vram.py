from accelerate.utils import calculate_maximum_sizes, convert_bytes, compute_module_sizes
from typing import Dict, List, Tuple
import torch
DTYPE_MODIFIER = { # byte
        torch.float32: 4,
        torch.float16: 2,
        torch.int8: 1,
        torch.int32: 4,
        torch.int64: 8,
    }

def get_all_layer_size(
    modules: List[Tuple[str, torch.nn.Module]], module_sizes: Dict[str, int], no_split_module_classes: List[str], modifier
):
    """
    from accelerate.utils get_max_layer_size
    Utility function that will scan a list of named modules and return the maximum size used by one full layer. The
    definition of a layer being:
    - a module with no direct children (just parameters and buffers)
    - a module whose class name is in the list `no_split_module_classes`

    Args:
        modules (`List[Tuple[str, torch.nn.Module]]`):
            The list of named modules where we want to determine the maximum layer size.
        module_sizes (`Dict[str, int]`):
            A dictionary mapping each layer name to its size (as generated by `compute_module_sizes`).
        no_split_module_classes (`List[str]`):
            A list of class names for layers we don't want to be split.

    Returns:
        `List[Tuple[str, str]]`: The size of all layer with the list of layer names and size str.
    """

    layer_sizes = []
    modules_to_treat = modules.copy()
    while len(modules_to_treat) > 0:
        module_name, module = modules_to_treat.pop(0)
        modules_children = list(module.named_children()) if isinstance(module, torch.nn.Module) else []
        if len(modules_children) == 0 or module.__class__.__name__ in no_split_module_classes:
            size = module_sizes[module_name]
            layer_sizes.append((module_name, convert_bytes(size / modifier)))
        else:
            modules_to_treat = [(f"{module_name}.{n}", v) for n, v in modules_children] + modules_to_treat

    return layer_sizes

def get_vram(model):
    no_split_modules = getattr(model, "_no_split_modules", None)
    if no_split_modules is None:
        no_split_modules = []
    modules_to_treat = (
            list(model.named_parameters(recurse=False))
            + list(model.named_children())
            + list(model.named_buffers(recurse=False))
    )
    sizes = compute_module_sizes(model)
    total_size = sizes[""]
    dtype = None
    for _, param in model.named_parameters():
        dtype = param.dtype
        break
    modifier = DTYPE_MODIFIER[dtype]
    total_size = convert_bytes(total_size / modifier)
    # List[Tuple[str, str]]
    all_layers = get_all_layer_size(modules_to_treat, sizes, no_split_modules, modifier)

    return total_size, all_layers