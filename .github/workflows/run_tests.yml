name: Unit Tests (GPU)

on:
  repository_dispatch:
  workflow_dispatch:

env:
  CUDA_DEVICE_ORDER: PCI_BUS_ID

jobs:
  build:
    runs-on: self-hosted
    container:
      image: modelcloud/gptqmodel:github-ci-v1
    steps:
      - name: Checkout Codes
        uses: actions/checkout@v4

      - name: Compile
        run: python setup.py bdist_wheel

      - name: Show dist folder
        run: ls -alh dist

      - name: Upload to artifact
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist


  test:
    needs: build
    runs-on: self-hosted
    container:
      image: modelcloud/gptqmodel:github-ci-v1
    strategy:
      fail-fast: false
      matrix:
        test-group:
          - gpu_group1
          - gpu_group2
    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist

      - name: Show dist folder
        run: ls -alh dist

      - name: Install wheel
        run: |
          # install only the last version
          pip install dist/*.whl

      - name: Find suitable GPU
        run: |
         suitable_gpu=$(nvidia-smi -L | grep "RTX 4090" | awk -F': ' '{print $1}' | sed 's/GPU //g' | while read gpu_id
          do
            mem_total=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits -i $gpu_id)
            mem_used=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits -i $gpu_id)
            mem_used_pct=$((100 * mem_used / mem_total))
            if [ $mem_used_pct -lt 2 ]; then # 2 -> 98% free
              echo $gpu_id
              break
            fi
          done)
          if [ -z "$suitable_gpu" ]; then
            echo "No suitable GPU found. Exiting with error."
            exit 1
          else
            echo "CUDA_VISIBLE_DEVICES=$suitable_gpu" >> $GITHUB_ENV
            echo "CUDA_VISIBLE_DEVICES set to $suitable_gpu"
          fi

      - name: Run tests group 1
        if: matrix.test-group == 'gpu_group1'
        run: pytest tests/test_perplexity.py

      - name: Run test_lm_head.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_lm_head.py

      - name: Run test_q4_exallama.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_exallama.py

      - name: Run test_q4_exallama_v2.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_exallama_v2.py

      - name: Run test_q4_marlin.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_marlin.py

      - name: Run test_q4_triton.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_triton.py

      - name: Run test_repacking.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_repacking.py

      - name: Run test_serialization.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_serialization.py

      - name: Run test_sharded.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_sharded.py

      - name: Run test_triton.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_triton.py

      - name: Run test_quant_formats.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_quant_formats.py

      - name: Run test_q4_cuda.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_cuda.py

      - name: Run test_q4_bitblas.py
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_bitblas.py
