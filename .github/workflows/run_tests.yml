name: Unit Tests (GPU)

on:
  repository_dispatch:
  workflow_dispatch:

env:
  CUDA_DEVICE_ORDER: PCI_BUS_ID

jobs:
  build:
    runs-on: self-hosted
    container:
      image: modelcloud/gptqmodel:github-ci-v1
    steps:
      - name: Checkout Codes
        id: check
        uses: actions/checkout@v4

      - name: Print results1
        run: |
          name=check
          echo ${{ steps[$name].outcome }}

      - name: Compile
        run: python setup.py bdist_wheel

      - name: Show dist folder
        run: ls -alh dist

      - name: Upload to artifact
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist


  test:
    needs: build
    runs-on: self-hosted
    container:
      image: modelcloud/gptqmodel:github-ci-v1
    strategy:
      fail-fast: false
      matrix:
        test-group:
          - gpu_group1
          - gpu_group2
    steps:
      - name: Download artifact
        uses: actions/download-artifact@v4
        with:
          name: dist
          path: dist

      - name: Show dist folder
        run: ls -alh dist

      - name: Install wheel
        run: |
          # install only the last version
          pip install dist/*.whl

      - name: Find suitable GPU
        run: |
         suitable_gpu=$(nvidia-smi -L | grep "RTX 4090" | awk -F': ' '{print $1}' | sed 's/GPU //g' | while read gpu_id
          do
            mem_total=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits -i $gpu_id)
            mem_used=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits -i $gpu_id)
            mem_used_pct=$((100 * mem_used / mem_total))
            if [ $mem_used_pct -lt 2 ]; then # 2 -> 98% free
              echo $gpu_id
              break
            fi
          done)
          if [ -z "$suitable_gpu" ]; then
            echo "No suitable GPU found. Exiting with error."
            exit 1
          else
            echo "CUDA_VISIBLE_DEVICES=$suitable_gpu" >> $GITHUB_ENV
            echo "CUDA_VISIBLE_DEVICES set to $suitable_gpu"
          fi

      - name: Run tests group 1
        id: test_perplexity
        if: matrix.test-group == 'gpu_group1'
        run: pytest tests/test_perplexity.py

      - name: Run test_lm_head.py
        id: test_lm_head
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_lm_head.py

      - name: Run test_q4_exallama.py
        id: test_q4_exallama
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_exallama.py

      - name: Run test_q4_exallama_v2.py
        id: test_q4_exallama_v2
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_exallama_v2.py

      - name: Run test_q4_marlin.py
        id: test_q4_marlin
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_marlin.py

      - name: Run test_q4_triton.py
        id: test_q4_triton
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_triton.py

      - name: Run test_repacking.py
        id: test_repacking
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_repacking.py

      - name: Run test_serialization.py
        id: test_serialization
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_serialization.py

      - name: Run test_sharded.py
        id: test_sharded
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_sharded.py

      - name: Run test_triton.py
        id: test_triton
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_triton.py

      - name: Run test_quant_formats.py
        id: test_quant_formats
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_quant_formats.py

      - name: Run test_q4_cuda.py
        id: test_q4_cuda
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_cuda.py

      - name: Run test_q4_bitblas.py
        id: test_q4_bitblas
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: pytest tests/test_q4_bitblas.py

      - name: Print results
        continue-on-error: true
        if: matrix.test-group == 'gpu_group2'
        run: |
          steps=(test_perplexity test_lm_head test_q4_exallama test_q4_exallama_v2 test_q4_marlin test_q4_triton test_repacking test_serialization test_sharded test_triton test_quant_formats test_q4_cuda test_q4_bitblas)
          for step in "${steps[@]}"; do
            outcome="${{ steps.$step.outcome }}"
            if [ "$outcome" == "success" ]; then
              echo -e "\e[32m${step} Result: $outcome\e[0m"
            else
              echo -e "\e[31m${step} Result: $outcome\e[0m"
            fi
          done
